---
tags: Concept, CCS, EN
title: CCS Image-Triton Inference Server | en
GA: UA-155999456-1
---

{%hackmd @docsharedstyle/default %}
{%hackmd @docsharedstyle/twccheader-en %}
{%hackmd @docsharedstyle/ccs-image-icon-size %}

# <img class="ccsimgicon" src="https://cos.twcc.ai/SYS-MANUAL/uploads/upload_f55059e9d0a6ac45c44bcc0ec1bebff5.png"> Triton Inference Server


TWCC provides pay-as-you-go working environment of NGCâ€™s TensorRT Inference Server. The TensorRT inference server provides an inference service via an HTTP endpoint, allowing remote clients to request inferencing for any model that is being managed by the server. The TensorRT inference server itself is included in the TensorRT inference server container. External to the container, there are additional C++ and Python client libraries, and additional documentation at GitHub: Inference Server.

## <i class="fa fa-sticky-note" aria-hidden="true"></i> <span class="ccsimglist">Information of Image file version
</span> 

![](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_16ff54e48ef435764e0d3b0eb05e4b4e.png)



:::info
{%hackmd @docsharedstyle/note-en %}
`py3` and `py2` are Python version differences.
:::

<details class="docspoiler">

<summary><b>Click me to refer to the detailed version package information</b></summary>

- [tritonserver-21.02-py3](https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel_21-02.html#rel_21-02)
- [tensorrtserver-20.02-py3](https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel_20-02.html#rel_20-02)
- [tensorrtserver-19.02-py3-v1](https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel_19-02.html#rel_19-02)
- [tensorrtserver-18.12-py3-v1](https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel_18.12.html#rel_18.12)
- [tensorrtserver-18.10-py3-v1](https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel_18.10.html#rel_18.10)
- [tensorrtserver-18.08.1-py3-v1](https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel_18.08.html#rel_18.08)
- [tensorrtserver-18.08.1-py2-v1](https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel_18.08.html#rel_18.08)

</details>
